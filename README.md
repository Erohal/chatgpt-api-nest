# ChatGPT API Powered By NestJS

Hi there,

This is a ChatGPT back-end written based on NestJS, which supports basic user registration and login, as well as JWT authentication, and supports two types of transmission modes.

1. Streaming transmission. After requesting the interface, RequestId is returned. Then use this Id to request the SSE interface to obtain the Token stream, in the format below.

```typescript
{
  /** Compl Id returned by OpenAI */
  id: string
  /** Single Token */
  delta: string
  /** finish_reason returns null before this last Chunk */
  finish_reason: string
}
```

2. Regular transmission. If many characters are generated and the waiting time is long, it is recommended to use streaming transmission first. The return format is as follows.

```typescript
{
  /** Compl Id returned by OpenAI */
  id: string
  /** Complete answer, note that there may be leading line breaks \n\n */
  content: string
  /** Reason for ending the response: null or stop or length */
  finish_reason: string,
  usage: {
    /** Number of tokens consumed by the prompt in this question */
    prompt_tokens: number,
    /** Number of tokens consumed by the answer in this question */
    completion_tokens: number,
    /** Total consumption: prompt_tokens + completion_tokens */
    total_tokens: number
  }
}
```

## Usage

1. Modify the database configuration and initial OpenAi Api Key configuration in `.env.example` and change its name to `.env`.
2. Install dependencies and synchronize database models.

```shell
yarn && prisma migrate dev
```

3. Start `next dev` or `next build && next start`. The default working port is 3000.

## Interfaces

1. POST /auth/login

```typescript
// Request
{
	username: string,
	password: string
}
// Response
{
    /** JWT Token */
    access_token: string
}
```

2. POST /auth/register

```typescript
// Request
{
	username: string,
	password: string
}
// Response
{
    sub: string
    username: string
}
```

3. POST /chat/process

```typescript
// Request With JWT
{
	// Automatically generated by the system if left blank, and context is carried with session_id requests later
	session_id?: string,
	message: string,
	stream?: boolean
}
// Response for streaming requests
{
    session_id: string,
    request_id: string
}
// Response for normal requests
{
  id: string,
  content: string,
  finish_reason: string,
  usage: {
    prompt_tokens: number,
    completion_tokens: number,
    total_tokens: number
  }
}
```

4. GET /chat/process/:requestId

```typescript
// SSE With JWT, it is recommended to use EventSourcePolyfill in combination
{
    id: string,
    delta: string
}
```
