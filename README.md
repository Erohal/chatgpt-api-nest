# ChatGPT API Powered By NestJS

Hi there,

This is a ChatGPT back-end written based on NestJS, which supports basic user registration and login, as well as JWT authentication, and supports two types of transmission modes.

This server implementation includes the storage of historical conversation data and supports handling when tokens exceed the limit. The details can be found in `openai.service.ts`. By default, 1000 tokens are kept for responses, but if using GPT-4, the range can be adjusted as needed.

Here is a brief introduction to two common transmission methods:

1. Streaming transmission. After requesting the interface, RequestId is returned. Then use this Id to request the SSE interface to obtain the Token stream, in the format below.

```typescript
{
  /** Compl Id returned by OpenAI */
  id: string
  /** Single Token */
  delta: string
  /** finish_reason returns null before this last Chunk */
  finish_reason: string
}
```

2. Regular transmission. If many characters are generated and the waiting time is long, it is recommended to use streaming transmission first. The return format is as follows.

```typescript
{
  /** Compl Id returned by OpenAI */
  id: string
  /** Complete answer, note that there may be leading line breaks \n\n */
  content: string
  /** Reason for ending the response: null or stop or length */
  finish_reason: string,
  usage: {
    /** Number of tokens consumed by the prompt in this question */
    prompt_tokens: number,
    /** Number of tokens consumed by the answer in this question */
    completion_tokens: number,
    /** Total consumption: prompt_tokens + completion_tokens */
    total_tokens: number
  }
}
```

## Usage

1. Modify the database configuration and initial OpenAi Api Key configuration in `.env.example` and change its name to `.env`.
2. Prepare the Postgres database.
3. Install dependencies and synchronize database models.

```shell
yarn && prisma migrate dev
```

3. Start `next dev` or `next build && next start`. The default working port is 3000.

## Docker

1. Use `docker build -t erohal/chatgpt-api-nest:latest` to build the container.
2. Start the container using `docker-compose -f docker-compose.yml`.

## Interfaces

1. POST /auth/login

```typescript
// Request
{
	username: string,
	password: string
}
// Response
{
    /** JWT Token */
    access_token: string
}
```

2. POST /auth/register

```typescript
// Request
{
	username: string,
	password: string
}
// Response
{
    sub: string
    username: string
}
```

3. POST /chat/process

```typescript
// Request With JWT
{
	// Automatically generated by the system if left blank, and context is carried with session_id requests later
	session_id?: string,
	message: string,
	stream?: boolean
}
// Response for streaming requests
{
    session_id: string,
    request_id: string
}
// Response for normal requests
{
  id: string,
  content: string,
  finish_reason: string,
  usage: {
    prompt_tokens: number,
    completion_tokens: number,
    total_tokens: number
  }
}
```

4. GET /chat/process/:requestId

```typescript
// SSE With JWT, it is recommended to use EventSourcePolyfill in combination
{
    id: string,
    delta: string
}
```
